# finetune_qwen_0_6b_final.py
"""
Qwen-0.6B æ–‡æœ¬åˆ†ç±»å¾®è°ƒ | ç»ˆæä¿®å¤ç‰ˆ
âœ… è§£å†³ï¼šLoRA æ— æ¢¯åº¦ã€FP16 ç¼©æ”¾é”™è¯¯ã€pad_token é—®é¢˜
"""

import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["BITSANDBYTES_NOWELCOME"] = "1"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# =======================
# ğŸ›¡ï¸ å¼ºåˆ¶å±è”½ bitsandbytesï¼ˆé¿å… CUDA é”™è¯¯ï¼‰
# =======================
import sys
from types import ModuleType

def create_fake_bitsandbytes():
    if "bitsandbytes" in sys.modules:
        return
    bnb = ModuleType("bitsandbytes")
    bnb.__spec__ = type('spec', (), {'loader': None})()
    bnb.__file__ = None
    bnb.nn = ModuleType("bitsandbytes.nn")
    bnb.nn.modules = ModuleType("bitsandbytes.nn.modules")
    sys.modules["bitsandbytes"] = bnb
    sys.modules["bitsandbytes.nn"] = bnb.nn
    sys.modules["bitsandbytes.nn.modules"] = bnb.nn.modules

create_fake_bitsandbytes()

# =======================
# âœ… å¯¼å…¥ä¾èµ–
# =======================
import torch
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    TrainingArguments,
    DataCollatorWithPadding,
    Trainer
)
from peft import LoraConfig, get_peft_model
from datasets import load_dataset

# =======================
# 1. è·¯å¾„é…ç½®
# =======================
model_path = "../Qwen3-0.6B"
data_path = "train_processed.parquet"
output_dir = "./qwen-0.6b-prompt-sentiment-lora"

# =======================
# 2. åŠ è½½ tokenizer
# =======================
print("ğŸ”„ åŠ è½½ tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

# âœ… è®¾ç½® pad_token
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.pad_token_id = tokenizer.eos_token_id
tokenizer.padding_side = "right"  # æ¨è

print(f"âœ… pad_token: {tokenizer.pad_token} (id={tokenizer.pad_token_id})")

# =======================
# 3. åŠ è½½æ¨¡å‹ï¼ˆFP16 + GPUï¼‰
# =======================
print("ğŸ”„ åŠ è½½æ¨¡å‹...")
model = AutoModelForSequenceClassification.from_pretrained(
    model_path,
    num_labels=2,  # äºŒåˆ†ç±»ï¼špositive vs negative/neutral
    torch_dtype=torch.float16,      # æ˜¾å­˜ä¼˜åŒ–
    device_map="auto",              # è‡ªåŠ¨åˆ†é…
    trust_remote_code=True
)

# âœ… å…³é”®ï¼šè®¾ç½® model.config.pad_token_id
if model.config.pad_token_id is None:
    model.config.pad_token_id = tokenizer.pad_token_id
print(f"âœ… model.config.pad_token_id: {model.config.pad_token_id}")

# =======================
# 4. LoRA é…ç½® + å¼ºåˆ¶å¯ç”¨æ¢¯åº¦
# =======================
lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules="all-linear",        # è‡ªåŠ¨åŒ¹é…æ‰€æœ‰çº¿æ€§å±‚
    lora_dropout=0.05,
    bias="none",
    modules_to_save=["score"],          # ä¿ç•™åˆ†ç±»å¤´
    task_type="SEQ_CLS"
)

print("ğŸ”§ æ·»åŠ  LoRA é€‚é…å™¨...")
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

# âœ… å¼ºåˆ¶å¯ç”¨ score å±‚æ¢¯åº¦ï¼ˆå…³é”®ï¼ï¼‰
print("âœ… å¼ºåˆ¶å¯ç”¨ score å±‚æ¢¯åº¦")
model.score.requires_grad_(True)

# âœ… ç¡®ä¿æ‰€æœ‰ LoRA å‚æ•°å¯è®­ç»ƒ
print("ğŸ” ç¡®ä¿ LoRA å‚æ•°å¯è®­ç»ƒ...")
for name, param in model.named_parameters():
    if "lora_" in name or "score" in name:
        param.requires_grad = True

# å†æ¬¡æ£€æŸ¥
print("\nâœ… æœ€ç»ˆå¯è®­ç»ƒå‚æ•°ï¼š")
model.print_trainable_parameters()  # åº”æ˜¾ç¤º > 0

# =======================
# 5. åŠ è½½æ•°æ®é›†
# =======================
print("ğŸ“Š åŠ è½½æ•°æ®é›†...")
dataset = load_dataset("parquet", data_files=data_path, split="train")
print(f"âœ… æ•°æ®é›†å¤§å°: {len(dataset):,}")

# æ ‡ç­¾æ˜ å°„
def map_sentiment(label):
    if isinstance(label, str):
        return 1 if label.strip().lower() == "positive" else 0
    return 0

# åˆ†è¯
def tokenize_function(examples):
    texts = examples["prompt"]
    labels = [map_sentiment(lbl) for lbl in examples["prompt_sentiment"]]
    encodings = tokenizer(
        texts,
        truncation=True,
        padding="max_length",
        max_length=512,
        return_tensors=None,
        return_attention_mask=True
    )
    encodings["labels"] = labels
    return encodings

# å¤„ç†
remove_columns = [
    "prompt", "response_a", "response_b", "prompt_sentiment",
    "id", "model_a", "model_b", "winner_model_a", "winner_model_b", "winner_tie"
]
dataset = dataset.map(
    tokenize_function,
    batched=True,
    remove_columns=remove_columns,
    num_proc=1,
    batch_size=1000,
)
dataset.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])

# =======================
# 6. è®­ç»ƒå‚æ•°
# =======================
print("âš™ï¸ é…ç½®è®­ç»ƒå‚æ•°...")
training_args = TrainingArguments(
    output_dir=output_dir,
    num_train_epochs=3,
    per_device_train_batch_size=16,  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
    gradient_accumulation_steps=4,   # ç­‰æ•ˆ batch_size = 64
    learning_rate=2e-5,
    lr_scheduler_type="cosine",
    warmup_ratio=0.1,
    logging_steps=10,
    save_strategy="epoch",
    save_total_limit=1,
    
    # --- å…³é”®ä¿®æ”¹ï¼šå¯ç”¨ FP16 å¹¶å¼€å¯æ¢¯åº¦ç¼©æ”¾ ---
    fp16=True,                       # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    # -----------------------------------------

    gradient_checkpointing=True,     # èŠ‚çœæ˜¾å­˜
    disable_tqdm=False,
    report_to="none",
    remove_unused_columns=False,     # é¿å…åˆ é™¤ 'label'
)

# =======================
# 7. åˆå§‹åŒ– Trainer
# =======================
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    data_collator=data_collator,
    tokenizer=tokenizer,
)

# =======================
# 9. å¼€å§‹è®­ç»ƒ
# =======================
print("ğŸš€ å¼€å§‹å¾®è°ƒ...")
try:
    trainer.train()
except Exception as e:
    print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
    raise

# =======================
# 10. ä¿å­˜ LoRA é€‚é…å™¨
# =======================
print("ğŸ’¾ ä¿å­˜å¾®è°ƒæƒé‡...")
model.save_pretrained(os.path.join(output_dir, "lora_adapter"))
tokenizer.save_pretrained(os.path.join(output_dir, "lora_adapter"))
print(f"âœ… å¾®è°ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ° {output_dir}/lora_adapter")